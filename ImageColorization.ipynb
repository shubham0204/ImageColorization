{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9exYVgtqDmGE",
    "colab_type": "text"
   },
   "source": [
    "The project is also available at GitHub here -> https://github.com/shubham0204/ImageColorization\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FER-2sf5Yghu",
    "colab_type": "text"
   },
   "source": [
    "# 1) Importing the libraries\n",
    "We import [TensorFlow](https://www.tensorflow.org/), [Numpy](http://www.numpy.org/) and [scikit-image](https://scikit-image.org/) module for playing around with images. Printing out the TensorFlow version is a good practice to see that everything is working fine. ( See [Colorizer.py](https://github.com/shubham0204/ImageColorization/blob/master/Colorizer.py) on GitHub )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Gvqkjy-uNnpe",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.activations import *\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import models\n",
    "from skimage.io import imshow , imsave\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print( tf.VERSION ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LV9qJFLlZKMv",
    "colab_type": "text"
   },
   "source": [
    "# 2) Loading the data\n",
    "We load the data which is stored in .npy files using the `np.load` method. We print out the shapes of the training and testing data.\n",
    "\n",
    "\n",
    "*   To convert your own images to .npy files, refer to the GitHub project and see the [Parser.py ](https://github.com/shubham0204/ImageColorization/blob/master/Parser.py)file.\n",
    "*   For sample data, download the three files from the [sample_data directory](https://github.com/shubham0204/ImageColorization/tree/master/sample_data) of the GitHub project.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "fHh6w4VRRFtx",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "X = np.load( 'X.npy' ) \n",
    "Y = np.load( 'Y.npy' ) \n",
    "test_X = np.load( 'test_X.npy' ) \n",
    "\n",
    "print( X.shape ,Y.shape ) \n",
    "print( test_X.shape ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3qQrVizZg-d",
    "colab_type": "text"
   },
   "source": [
    "# 3) Defining the model\n",
    "We define our Convolutional Auto Encoder model using the Keras [Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential).\n",
    "\n",
    "\n",
    "*   We use a low dropout rate of 0.3,\n",
    "*   `DIMEN` is the dimension of the image which acts as an input to the model. In our case, it is 64 or the image has dimensions of 64px * 64px.\n",
    "\n",
    "We compile the model to use the Adam optimizer with a learning rate of 0.0001. The loss function is mean squared error and we output the `mae` or mean absolute error of the model during training. ( See [Colorizer.py](https://github.com/shubham0204/ImageColorization/blob/master/Colorizer.py) on GitHub )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "J6PMbuWKQhzA",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "dropout_rate = 0.5\n",
    "DIMEN = 64\n",
    "kernel_size = ( 4 , 4 )\n",
    "\n",
    "NEURAL_SCHEMA = [\n",
    "\n",
    "    Conv2D( 32 , input_shape=( DIMEN , DIMEN , 1 ) , kernel_size=kernel_size , strides=1,activation=relu),\n",
    "    Dropout( dropout_rate ) ,\n",
    "    Conv2D( 64, kernel_size=kernel_size, strides=1, activation=relu),\n",
    "    Dropout(dropout_rate),\n",
    "    Conv2D( 128, kernel_size=kernel_size, strides=1, activation=relu) ,\n",
    "    Dropout(dropout_rate),\n",
    "    Conv2D( 256, kernel_size=kernel_size, strides=1, activation=relu),\n",
    "    Dropout(dropout_rate),\n",
    "    Conv2DTranspose( 128, kernel_size=kernel_size, strides=1, activation=relu),\n",
    "    Dropout(dropout_rate),\n",
    "    Conv2DTranspose( 64, kernel_size=kernel_size, strides=1, activation=relu),\n",
    "    Dropout(dropout_rate),\n",
    "    Conv2DTranspose( 32, kernel_size=kernel_size, strides=1, activation=relu),\n",
    "    Dropout(dropout_rate),\n",
    "    Conv2DTranspose( 3, kernel_size=kernel_size, strides=1, activation=relu ),\n",
    "\n",
    "]\n",
    "\n",
    "model = tf.keras.Sequential( NEURAL_SCHEMA )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(0.0001),\n",
    "    loss=losses.mean_squared_error,\n",
    "    metrics=['mae'],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtWauJ_oa91F",
    "colab_type": "text"
   },
   "source": [
    "# 4) Training the model\n",
    "We train the model over the training dataset using the `fit()` method.  ( See [Colorizer.py](https://github.com/shubham0204/ImageColorization/blob/master/Colorizer.py) on GitHub )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsiYdr5yEiVr",
    "colab_type": "text"
   },
   "source": [
    "**Note : If required, load the model which was trained earlier or use the model located in the [models](https://github.com/shubham0204/ImageColorization/tree/master/models) directory on GitHub.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Nr9XCkZbEi0S",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "model = models.load_model( 'model.h5' ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "BENB4VEVRakX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "model.fit(\n",
    "    X, \n",
    "    Y, \n",
    "    batch_size=3 , \n",
    "    epochs=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeyH6qRrct1v",
    "colab_type": "text"
   },
   "source": [
    "We save the model to export it or download it to our local machine using `model.save()` method. **Tip : To use it on an Android or iOS device, use [this notebook](https://colab.research.google.com/drive/1IUIn9ffk5ICKujqPyuGaHL2irQ9Wmtpm) to convert the model.h5 to a [TensorFlow Lite](https://www.tensorflow.org/lite) model ( .tflite ).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "I9rObwqpcslp",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "model.save( 'model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KpZXzxfboy5",
    "colab_type": "text"
   },
   "source": [
    "# 5) Colorizing the images\n",
    "\n",
    "\n",
    "\n",
    "1.   We take the grayscale images and feed them to our model\n",
    "2.   To avoid negative values, we perform a operation to convert all negative values to 0.\n",
    "3.   We multiply the values by 255 ( the images used for training were normalised ).\n",
    "4.   Convert the values to a image array using `imsave( )` method.\n",
    "\n",
    "( See [MainFile.py ](https://github.com/shubham0204/ImageColorization/blob/master/MainFile.py)on GitHub )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "yCY8ZIkARpLx",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "values = model.predict( test_X )\n",
    "values = np.maximum( values , 0 )\n",
    "\n",
    "for i in range( 6 ):\n",
    "    image_final = ( values[i] * 255).astype( np.uint8 )\n",
    "    imsave( '{}.png'.format( i + 1 ) , image_final  )\n",
    "    imshow( image_final )\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ImageColorization.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "private_outputs": true,
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
